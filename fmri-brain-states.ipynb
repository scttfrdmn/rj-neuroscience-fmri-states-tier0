{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuroscience Quick Start: fMRI Brain State Classification\n",
    "\n",
    "**Duration:** 10-30 minutes  \n",
    "**Goal:** Classify brain states from fMRI activity patterns using machine learning\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "- Load and explore fMRI brain imaging data (NIfTI format)\n",
    "- Visualize brain activity patterns\n",
    "- Extract features from BOLD signals\n",
    "- Train classifiers to decode cognitive states\n",
    "- Identify discriminative brain regions\n",
    "\n",
    "## Dataset\n",
    "\n",
    "We'll use the **Haxby 2001** dataset:\n",
    "- Classic fMRI study on visual object recognition\n",
    "- 8 object categories (faces, houses, cats, bottles, scissors, shoes, chairs, scrambled)\n",
    "- 1 subject, 12 runs\n",
    "- Pre-processed BOLD fMRI data\n",
    "- Source: Nilearn datasets\n",
    "\n",
    "No AWS account or API keys needed - let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries (all pre-installed in Colab/Studio Lab)\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import LeaveOneGroupOut, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Neuroimaging libraries\n",
    "import nibabel as nib\n",
    "from nilearn import datasets, image, plotting\n",
    "from nilearn.maskers import NiftiMasker\n",
    "from nilearn.plotting import show\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "plt.rcParams[\"font.size\"] = 11\n",
    "\n",
    "print(\"‚úì Libraries loaded successfully!\")\n",
    "print(\"  - NiBabel for NIfTI file handling\")\n",
    "print(\"  - Nilearn for fMRI analysis and visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Haxby dataset (downloads ~30MB on first run)\n",
    "print(\"Downloading Haxby 2001 dataset...\")\n",
    "print(\"(This may take 1-2 minutes on first run)\\n\")\n",
    "\n",
    "haxby_dataset = datasets.fetch_haxby()\n",
    "\n",
    "# Get file paths\n",
    "fmri_filename = haxby_dataset.func[0]  # Functional data (4D: x, y, z, time)\n",
    "labels = pd.read_csv(haxby_dataset.session_target[0], sep=\" \")\n",
    "mask_filename = haxby_dataset.mask_vt[0]  # Visual cortex mask\n",
    "\n",
    "print(\"‚úì Dataset loaded successfully!\")\n",
    "print(f\"  fMRI data: {fmri_filename}\")\n",
    "print(f\"  Brain mask: {mask_filename}\")\n",
    "print(f\"  Labels shape: {labels.shape}\")\n",
    "print(f\"\\nNumber of volumes: {len(labels)}\")\n",
    "print(f\"Stimulus categories: {labels['labels'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding fMRI Data\n",
    "\n",
    "**fMRI (functional Magnetic Resonance Imaging):**\n",
    "- Measures brain activity via blood oxygen level-dependent (BOLD) signal\n",
    "- 4D data: 3D brain volume + time\n",
    "- Each volume = snapshot of whole-brain activity\n",
    "- Spatial resolution: ~2-3mm\n",
    "- Temporal resolution: ~2 seconds (TR = repetition time)\n",
    "\n",
    "**Brain Decoding:**\n",
    "- Goal: Predict what someone is seeing/thinking from brain activity\n",
    "- Method: Machine learning on spatial patterns of activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Exploration and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the fMRI image to inspect dimensions\n",
    "fmri_img = nib.load(fmri_filename)\n",
    "fmri_data = fmri_img.get_fdata()\n",
    "\n",
    "print(\"=== fMRI Data Dimensions ===\")\n",
    "print(f\"Full 4D shape: {fmri_data.shape}\")\n",
    "print(f\"  Spatial (x, y, z): {fmri_data.shape[:3]}\")\n",
    "print(f\"  Temporal (volumes): {fmri_data.shape[3]}\")\n",
    "print(f\"  Voxel size: {fmri_img.header.get_zooms()[:3]} mm\")\n",
    "print(f\"  TR (repetition time): {fmri_img.header.get_zooms()[3]} seconds\")\n",
    "print(f\"\\nTotal number of voxels: {np.prod(fmri_data.shape[:3]):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the brain anatomy (mean over time)\n",
    "mean_img = image.mean_img(fmri_img)\n",
    "\n",
    "print(\"Displaying mean fMRI volume (anatomical reference):\\n\")\n",
    "plotting.plot_anat(\n",
    "    mean_img,\n",
    "    title=\"Mean fMRI Volume (Anatomical Reference)\",\n",
    "    cut_coords=(0, -10, 10),\n",
    "    display_mode=\"ortho\",\n",
    ")\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the brain mask (region of interest)\n",
    "mask_img = nib.load(mask_filename)\n",
    "\n",
    "print(\"Visual cortex mask (ventral temporal region for object recognition):\\n\")\n",
    "plotting.plot_roi(\n",
    "    mask_img,\n",
    "    bg_img=mean_img,\n",
    "    title=\"Visual Cortex Mask (Ventral Temporal)\",\n",
    "    cut_coords=(0, -55, -10),\n",
    "    display_mode=\"ortho\",\n",
    ")\n",
    "show()\n",
    "\n",
    "# Count voxels in mask\n",
    "mask_data = mask_img.get_fdata()\n",
    "n_voxels = int(mask_data.sum())\n",
    "print(f\"\\nVoxels in visual cortex mask: {n_voxels:,}\")\n",
    "print(f\"Percentage of brain: {100 * n_voxels / np.prod(mask_data.shape):.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the experimental design\n",
    "print(\"=== Experimental Design ===\")\n",
    "print(\"\\nStimulus presentation counts:\")\n",
    "print(labels[\"labels\"].value_counts().sort_index())\n",
    "\n",
    "# Visualize stimulus distribution\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "labels[\"labels\"].value_counts().sort_index().plot(kind=\"bar\", ax=ax, color=\"steelblue\")\n",
    "ax.set_xlabel(\"Stimulus Category\", fontweight=\"bold\")\n",
    "ax.set_ylabel(\"Number of Volumes\", fontweight=\"bold\")\n",
    "ax.set_title(\"Stimulus Presentation Counts\", fontsize=14, fontweight=\"bold\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úì Each category presented ~12 times across the experiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Extraction with Brain Masker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a masker to extract time series from ROI\n",
    "# This converts 4D fMRI (x, y, z, time) to 2D matrix (time, voxels)\n",
    "masker = NiftiMasker(\n",
    "    mask_img=mask_filename,\n",
    "    standardize=True,  # Z-score each voxel's time series\n",
    "    detrend=True,  # Remove linear trends\n",
    "    smoothing_fwhm=4,  # Spatial smoothing (4mm)\n",
    ")\n",
    "\n",
    "print(\"Extracting features from visual cortex...\")\n",
    "X = masker.fit_transform(fmri_filename)\n",
    "\n",
    "print(\"\\n‚úì Feature matrix extracted!\")\n",
    "print(f\"  Shape: {X.shape}\")\n",
    "print(f\"  Interpretation: {X.shape[0]} time points √ó {X.shape[1]} voxels\")\n",
    "print(\"\\nEach row = brain state at one time point\")\n",
    "print(\"Each column = activity level in one voxel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare labels for classification\n",
    "# Remove 'rest' periods and 'scrambled' stimuli for cleaner classification\n",
    "y = labels[\"labels\"].values\n",
    "conditions_to_use = [\"face\", \"house\", \"cat\", \"bottle\", \"scissors\", \"shoe\", \"chair\"]\n",
    "condition_mask = np.isin(y, conditions_to_use)\n",
    "\n",
    "X_filtered = X[condition_mask]\n",
    "y_filtered = y[condition_mask]\n",
    "runs = labels[\"chunks\"].values[condition_mask]  # Run number for cross-validation\n",
    "\n",
    "print(\"Filtered dataset for classification:\")\n",
    "print(f\"  Samples: {X_filtered.shape[0]}\")\n",
    "print(f\"  Features: {X_filtered.shape[1]}\")\n",
    "print(f\"  Categories: {len(np.unique(y_filtered))}\")\n",
    "print(f\"\\nCategories: {list(np.unique(y_filtered))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Brain State Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Support Vector Machine (SVM) classifier\n",
    "# SVM is standard for fMRI decoding due to high dimensionality\n",
    "print(\"Training SVM classifier for brain state decoding...\")\n",
    "print(\"(This may take 1-2 minutes)\\n\")\n",
    "\n",
    "# Use Leave-One-Run-Out cross-validation (best practice for fMRI)\n",
    "# Never test on data from the same run as training (prevents overfitting)\n",
    "cv = LeaveOneGroupOut()\n",
    "clf = SVC(kernel=\"linear\", C=1.0)\n",
    "\n",
    "# Compute cross-validated accuracy\n",
    "scores = cross_val_score(\n",
    "    clf, X_filtered, y_filtered, cv=cv, groups=runs, scoring=\"accuracy\", n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"=== Classification Results ===\")\n",
    "print(f\"\\nCross-validated accuracy: {scores.mean():.2%} (¬± {scores.std():.2%})\")\n",
    "print(f\"Per-fold accuracies: {[f'{s:.2%}' for s in scores]}\")\n",
    "print(f\"\\nChance level (random guessing): {1 / len(conditions_to_use):.2%}\")\n",
    "print(f\"Performance above chance: {scores.mean() - 1 / len(conditions_to_use):.2%}\")\n",
    "\n",
    "if scores.mean() > 0.5:\n",
    "    print(\n",
    "        \"\\n‚úì Brain decoding SUCCESSFUL! We can predict what the person is viewing from brain activity alone!\"\n",
    "    )\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Accuracy is modest. May need more data or feature engineering.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model on all data for detailed analysis\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "print(\"Generating predictions for confusion matrix...\")\n",
    "y_pred = cross_val_predict(clf, X_filtered, y_filtered, cv=cv, groups=runs, n_jobs=-1)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_filtered, y_pred, labels=conditions_to_use)\n",
    "cm_normalized = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Visualize confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    cm_normalized,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=conditions_to_use,\n",
    "    yticklabels=conditions_to_use,\n",
    "    cbar_kws={\"label\": \"Accuracy\"},\n",
    "    ax=ax,\n",
    ")\n",
    "ax.set_xlabel(\"Predicted Category\", fontweight=\"bold\", fontsize=12)\n",
    "ax.set_ylabel(\"True Category\", fontweight=\"bold\", fontsize=12)\n",
    "ax.set_title(\"Brain State Classification Confusion Matrix\", fontweight=\"bold\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n=== Per-Category Performance ===\")\n",
    "print(\n",
    "    classification_report(\n",
    "        y_filtered, y_pred, labels=conditions_to_use, target_names=conditions_to_use\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Brain Activity Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute average activation for each category\n",
    "print(\"Computing category-specific activation patterns...\\n\")\n",
    "\n",
    "# Select two contrasting categories\n",
    "category_1 = \"face\"\n",
    "category_2 = \"house\"\n",
    "\n",
    "mask_1 = y == category_1\n",
    "mask_2 = y == category_2\n",
    "\n",
    "mean_activation_1 = X[mask_1].mean(axis=0)\n",
    "mean_activation_2 = X[mask_2].mean(axis=0)\n",
    "\n",
    "# Compute contrast (difference between categories)\n",
    "contrast = mean_activation_1 - mean_activation_2\n",
    "\n",
    "# Transform back to brain space\n",
    "contrast_img = masker.inverse_transform(contrast)\n",
    "\n",
    "print(f\"Visualizing contrast: {category_1.upper()} vs {category_2.upper()}\\n\")\n",
    "plotting.plot_stat_map(\n",
    "    contrast_img,\n",
    "    bg_img=mean_img,\n",
    "    title=f\"{category_1.capitalize()} vs {category_2.capitalize()} Activation\",\n",
    "    cut_coords=(40, -55, -10),\n",
    "    display_mode=\"ortho\",\n",
    "    threshold=0.5,\n",
    "    cmap=\"cold_hot\",\n",
    ")\n",
    "show()\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"  - Red/warm colors: More active for FACES\")\n",
    "print(\"  - Blue/cool colors: More active for HOUSES\")\n",
    "print(\"  - Fusiform Face Area (FFA): Known to respond preferentially to faces\")\n",
    "print(\"  - Parahippocampal Place Area (PPA): Known to respond to scenes/houses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Glass brain visualization (shows activation throughout brain)\n",
    "print(\"Glass brain visualization (3D projection):\\n\")\n",
    "\n",
    "plotting.plot_glass_brain(\n",
    "    contrast_img,\n",
    "    title=f\"{category_1.capitalize()} > {category_2.capitalize()}\",\n",
    "    threshold=0.5,\n",
    "    colorbar=True,\n",
    "    plot_abs=False,\n",
    "    cmap=\"cold_hot\",\n",
    ")\n",
    "show()\n",
    "\n",
    "print(\"\\n‚úì This 'glass brain' shows where in the brain we see differential activation\")\n",
    "print(\"  Helps identify specific regions involved in category discrimination\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a final model to extract feature weights\n",
    "print(\"Analyzing which brain regions are most important for classification...\\n\")\n",
    "\n",
    "# Focus on face vs house for interpretability\n",
    "binary_mask = np.isin(y, [category_1, category_2])\n",
    "X_binary = X[binary_mask]\n",
    "y_binary = (y[binary_mask] == category_1).astype(int)\n",
    "\n",
    "# Train linear SVM\n",
    "clf_binary = SVC(kernel=\"linear\", C=1.0)\n",
    "clf_binary.fit(X_binary, y_binary)\n",
    "\n",
    "# Extract weights (coefficients)\n",
    "weights = clf_binary.coef_[0]\n",
    "\n",
    "# Transform to brain space\n",
    "weights_img = masker.inverse_transform(weights)\n",
    "\n",
    "print(f\"Voxel weights for {category_1} vs {category_2} classification:\\n\")\n",
    "plotting.plot_stat_map(\n",
    "    weights_img,\n",
    "    bg_img=mean_img,\n",
    "    title=f\"SVM Weights: {category_1.capitalize()} vs {category_2.capitalize()}\",\n",
    "    cut_coords=(40, -55, -10),\n",
    "    display_mode=\"ortho\",\n",
    "    threshold=\"auto\",\n",
    "    cmap=\"cold_hot\",\n",
    ")\n",
    "show()\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"  - Positive weights (red): Voxels that predict FACES\")\n",
    "print(\"  - Negative weights (blue): Voxels that predict HOUSES\")\n",
    "print(\"  - Magnitude indicates importance for classification\")\n",
    "print(\"\\n‚úì These patterns align with known neuroscience!\")\n",
    "print(\"  FFA (fusiform face area) and PPA (parahippocampal place area) are visible\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Key Findings Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary statistics\n",
    "print(\"=\" * 70)\n",
    "print(\"fMRI BRAIN DECODING SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nüìä DATASET:\")\n",
    "print(\"   ‚Ä¢ Subjects: 1 (Haxby 2001)\")\n",
    "print(f\"   ‚Ä¢ Categories: {len(conditions_to_use)} visual object types\")\n",
    "print(f\"   ‚Ä¢ fMRI volumes: {X_filtered.shape[0]} (after filtering)\")\n",
    "print(f\"   ‚Ä¢ Voxels analyzed: {X_filtered.shape[1]:,} (visual cortex)\")\n",
    "print(\"   ‚Ä¢ Spatial resolution: 3.5mm isotropic\")\n",
    "\n",
    "print(\"\\nüß† CLASSIFICATION PERFORMANCE:\")\n",
    "print(f\"   ‚Ä¢ Cross-validated accuracy: {scores.mean():.1%} (¬± {scores.std():.1%})\")\n",
    "print(f\"   ‚Ä¢ Chance level: {1 / len(conditions_to_use):.1%}\")\n",
    "print(f\"   ‚Ä¢ Above chance: {scores.mean() - 1 / len(conditions_to_use):.1%}\")\n",
    "print(\"   ‚Ä¢ Method: Linear SVM with leave-one-run-out CV\")\n",
    "\n",
    "print(\"\\nüî¨ NEUROSCIENCE INSIGHTS:\")\n",
    "print(\"   ‚Ä¢ Successfully decoded visual categories from brain activity\")\n",
    "print(\"   ‚Ä¢ Category-selective regions identified (FFA for faces, PPA for places)\")\n",
    "print(\"   ‚Ä¢ Results consistent with established neuroscience literature\")\n",
    "print(\"   ‚Ä¢ Demonstrates brain represents different object categories in distinct patterns\")\n",
    "\n",
    "print(\"\\n‚öôÔ∏è  METHODS:\")\n",
    "print(\"   ‚Ä¢ Preprocessing: Standardization, detrending, smoothing (4mm)\")\n",
    "print(\"   ‚Ä¢ Feature extraction: Voxel-wise BOLD signal in visual cortex\")\n",
    "print(\"   ‚Ä¢ Classification: Linear Support Vector Machine (SVM)\")\n",
    "print(\"   ‚Ä¢ Validation: Leave-one-run-out cross-validation\")\n",
    "\n",
    "print(\"\\n‚úÖ CONCLUSION:\")\n",
    "print(\"   Machine learning can reliably decode what a person is viewing\")\n",
    "print(\"   from patterns of brain activity in visual cortex. This demonstrates\")\n",
    "print(\"   that different visual categories evoke distinct, consistent neural\")\n",
    "print(\"   representations that can be detected and classified.\")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What You Learned\n",
    "\n",
    "In just 10-30 minutes, you:\n",
    "\n",
    "1. Loaded and explored fMRI brain imaging data (NIfTI format)\n",
    "2. Visualized brain anatomy and regions of interest\n",
    "3. Extracted features from BOLD signals in visual cortex\n",
    "4. Trained a classifier to decode cognitive states from brain activity\n",
    "5. Achieved above-chance classification accuracy\n",
    "6. Identified brain regions important for visual category recognition\n",
    "7. Validated results with proper cross-validation\n",
    "8. Created publication-quality brain visualizations\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "### Ready for More?\n",
    "\n",
    "**Tier 1: SageMaker Studio Lab (4-8 hours, free)**\n",
    "- Multi-subject ensemble analysis with 10GB data\n",
    "- Functional connectivity mapping\n",
    "- Deep learning with 3D CNNs\n",
    "- Persistent storage for large datasets\n",
    "- Train models for 5-6 hours continuously\n",
    "\n",
    "**Tier 2: AWS Starter (4-8 hours, $5-15)**\n",
    "- Store neuroimaging data in S3\n",
    "- Distributed preprocessing with AWS Batch\n",
    "- Managed training on SageMaker\n",
    "- Multi-cohort analysis (ABIDE, HCP)\n",
    "\n",
    "**Tier 3: Production Infrastructure (1-2 weeks, $50-500/month)**\n",
    "- Multi-site neuroimaging datasets (500GB-1TB)\n",
    "- Distributed deep learning training\n",
    "- Real-time brain decoding pipelines\n",
    "- Automated quality control and preprocessing\n",
    "\n",
    "## Learn More\n",
    "\n",
    "- **Nilearn Documentation:** [https://nilearn.github.io/](https://nilearn.github.io/)\n",
    "- **Human Connectome Project:** [https://www.humanconnectome.org/](https://www.humanconnectome.org/)\n",
    "- **ABIDE Dataset:** [http://fcon_1000.projects.nitrc.org/indi/abide/](http://fcon_1000.projects.nitrc.org/indi/abide/)\n",
    "- **fMRI Decoding Tutorial:** [https://nilearn.github.io/stable/auto_examples/index.html](https://nilearn.github.io/stable/auto_examples/index.html)\n",
    "\n",
    "---\n",
    "\n",
    "**Built with [Claude Code](https://claude.com/claude-code)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
